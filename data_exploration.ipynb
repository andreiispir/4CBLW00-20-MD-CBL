{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e35ae659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9128adf2",
   "metadata": {},
   "source": [
    "Loading data from the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0067afa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1...\n",
      "Processing chunk 2...\n",
      "Processing chunk 3...\n",
      "Processing chunk 4...\n",
      "Processing chunk 5...\n",
      "Processing chunk 6...\n",
      "Processing chunk 7...\n",
      "Processing chunk 8...\n",
      "Processing chunk 9...\n",
      "Processing chunk 10...\n",
      "Processing chunk 11...\n",
      "Processing chunk 12...\n",
      "Processing chunk 13...\n",
      "Processing chunk 14...\n",
      "Processing chunk 15...\n",
      "Processing chunk 16...\n",
      "Processing chunk 17...\n",
      "Processing chunk 18...\n",
      "Processing chunk 19...\n",
      "Processing chunk 20...\n",
      "Processing chunk 21...\n",
      "Processing chunk 22...\n",
      "Processing chunk 23...\n",
      "Processing chunk 24...\n",
      "Processing chunk 25...\n",
      "Processing chunk 26...\n",
      "Processing chunk 27...\n",
      "Processing chunk 28...\n",
      "Processing chunk 29...\n",
      "Processing chunk 30...\n",
      "Processing chunk 31...\n",
      "Processing chunk 32...\n",
      "Processing chunk 33...\n",
      "Processing chunk 34...\n",
      "Processing chunk 35...\n",
      "Processing chunk 36...\n",
      "Processing chunk 37...\n",
      "Processing chunk 38...\n",
      "Processing chunk 39...\n",
      "Processing chunk 40...\n",
      "Processing chunk 41...\n",
      "Processing chunk 42...\n",
      "Processing chunk 43...\n",
      "Processing chunk 44...\n",
      "Processing chunk 45...\n",
      "Processing chunk 46...\n",
      "Processing chunk 47...\n",
      "Processing chunk 48...\n",
      "Processing chunk 49...\n",
      "Processing chunk 50...\n",
      "Processing chunk 51...\n",
      "Processing chunk 52...\n",
      "Processing chunk 53...\n",
      "Processing chunk 54...\n",
      "Processing chunk 55...\n",
      "Processing chunk 56...\n",
      "Processing chunk 57...\n",
      "Processing chunk 58...\n",
      "Processing chunk 59...\n",
      "Processing chunk 60...\n",
      "Processing chunk 61...\n",
      "Processing chunk 62...\n",
      "Processing chunk 63...\n",
      "Processing chunk 64...\n",
      "Processing chunk 65...\n",
      "Processing chunk 66...\n",
      "Processing chunk 67...\n",
      "Processing chunk 68...\n",
      "Processing chunk 69...\n",
      "Processing chunk 70...\n",
      "Processing chunk 71...\n",
      "Processing chunk 72...\n",
      "Processing chunk 73...\n",
      "Processing chunk 74...\n",
      "Processing chunk 75...\n",
      "Processing chunk 76...\n",
      "Processing chunk 77...\n",
      "Processing chunk 78...\n",
      "Processing chunk 79...\n",
      "Processing chunk 80...\n",
      "Processing chunk 81...\n",
      "Processing chunk 82...\n",
      "Processing chunk 83...\n",
      "Processing chunk 84...\n",
      "Processing chunk 85...\n",
      "Processing chunk 86...\n",
      "Processing chunk 87...\n",
      "Processing chunk 88...\n",
      "Processing chunk 89...\n",
      "Processing chunk 90...\n",
      "Processing chunk 91...\n",
      "Processing chunk 92...\n",
      "Processing chunk 93...\n",
      "Processing chunk 94...\n",
      "Processing chunk 95...\n",
      "Processing chunk 96...\n",
      "Processing chunk 97...\n",
      "Processing chunk 98...\n",
      "Processing chunk 99...\n",
      "Processing chunk 100...\n",
      "Loaded 27205378 good rows.\n",
      "Skipped 0 bad rows.\n"
     ]
    }
   ],
   "source": [
    "# Setting up path to load file\n",
    "current_dir = os.getcwd()\n",
    "csv_filename = 'data.csv'  \n",
    "csv_path = os.path.join(current_dir, csv_filename)\n",
    "\n",
    "# Initialize counter\n",
    "bad_line_counter = 0\n",
    "\n",
    "# Define a function to handle bad lines\n",
    "def handle_bad_line(bad_line):\n",
    "    global bad_line_counter\n",
    "    bad_line_counter += 1\n",
    "    return None  # Skip the bad line\n",
    "\n",
    "# Read it in chunks due to huge size\n",
    "chunk_size = 1_500_000\n",
    "\n",
    "# Keep only relevant columns, remove ones with lots of NaN values\n",
    "# LSOA name removed due to redundance\n",
    "# Last outcome category removed due to high number of NaN values: 87 482 715 / 149 351 274 \n",
    "# Context removed due to high number of NaN values: 144 750 473 / 149 351 274 \n",
    "# Crime ID removed due to high number of NaN values: 5 781 005 / 27 205 384 (London)\n",
    "\n",
    "columns_to_keep = ['Month', 'Reported by', 'Falls within', 'Latitude', 'Longitude', 'Location', 'LSOA code', 'Crime type']\n",
    "chunks = pd.read_csv(csv_path, \n",
    "                     chunksize=chunk_size,\n",
    "                     usecols=columns_to_keep,\n",
    "                     engine='python', \n",
    "                     on_bad_lines=handle_bad_line)\n",
    "\n",
    "dfs = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "\n",
    "    # Removing NaN values from certain columns\n",
    "    # Coordinates because it is not possible to find out then if it is in london or not\n",
    "    # LSOA because it is only 6 values from London, hard to later assign police officers\n",
    "    chunk = chunk.dropna(subset=['Latitude', 'Longitude', 'LSOA code'])\n",
    "\n",
    "    # Keep only rows inside London's coordinated obtained from Wikipedia\n",
    "    lat_min, lat_max = 51.2867602, 51.6918741\n",
    "    lon_min, lon_max = -0.5103751, 0.3340155\n",
    "\n",
    "    chunk = chunk[\n",
    "        (chunk['Latitude'] >= lat_min) & (chunk['Latitude'] <= lat_max) &\n",
    "        (chunk['Longitude'] >= lon_min) & (chunk['Longitude'] <= lon_max)\n",
    "    ]\n",
    "    # Printing progress\n",
    "    print(f\"Processing chunk {i+1}...\")\n",
    "    dfs.append(chunk)\n",
    "\n",
    "df_london = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(f\"Loaded {len(df_london)} good rows.\")\n",
    "print(f\"Skipped {bad_line_counter} bad rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04413b42",
   "metadata": {},
   "source": [
    "Printing head to see the Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94028829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Reported by</th>\n",
       "      <th>Falls within</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>LSOA code</th>\n",
       "      <th>Crime type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12</td>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>0.165776</td>\n",
       "      <td>51.5442</td>\n",
       "      <td>On or near Dagenham East</td>\n",
       "      <td>E01000036</td>\n",
       "      <td>Anti-social behaviour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-12</td>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>0.165776</td>\n",
       "      <td>51.5442</td>\n",
       "      <td>On or near Dagenham East</td>\n",
       "      <td>E01000036</td>\n",
       "      <td>Anti-social behaviour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-12</td>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>0.165776</td>\n",
       "      <td>51.5442</td>\n",
       "      <td>On or near Dagenham East</td>\n",
       "      <td>E01000036</td>\n",
       "      <td>Violent crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-12</td>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>0.165776</td>\n",
       "      <td>51.5442</td>\n",
       "      <td>On or near Dagenham East</td>\n",
       "      <td>E01000036</td>\n",
       "      <td>Violent crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-12</td>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>0.165776</td>\n",
       "      <td>51.5442</td>\n",
       "      <td>On or near Dagenham East</td>\n",
       "      <td>E01000036</td>\n",
       "      <td>Violent crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Month               Reported by              Falls within  Longitude  \\\n",
       "0  2010-12  British Transport Police  British Transport Police   0.165776   \n",
       "1  2010-12  British Transport Police  British Transport Police   0.165776   \n",
       "2  2010-12  British Transport Police  British Transport Police   0.165776   \n",
       "3  2010-12  British Transport Police  British Transport Police   0.165776   \n",
       "4  2010-12  British Transport Police  British Transport Police   0.165776   \n",
       "\n",
       "   Latitude                  Location  LSOA code             Crime type  \n",
       "0   51.5442  On or near Dagenham East  E01000036  Anti-social behaviour  \n",
       "1   51.5442  On or near Dagenham East  E01000036  Anti-social behaviour  \n",
       "2   51.5442  On or near Dagenham East  E01000036          Violent crime  \n",
       "3   51.5442  On or near Dagenham East  E01000036          Violent crime  \n",
       "4   51.5442  On or near Dagenham East  E01000036          Violent crime  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_london.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1535cd",
   "metadata": {},
   "source": [
    "Counting NaN values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2273b221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Month': 0,\n",
       " 'Reported by': 0,\n",
       " 'Falls within': 0,\n",
       " 'Longitude': 0,\n",
       " 'Latitude': 0,\n",
       " 'Location': 0,\n",
       " 'LSOA code': 0,\n",
       " 'Crime type': 0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_nans(df):\n",
    "    \"\"\"\n",
    "    Count NaN values in each column of a df object\n",
    "    Input:\n",
    "    - df: df object obtained from data\n",
    "    Returns:\n",
    "    - dictionary with numbers of NaN values for each column\n",
    "    \"\"\"\n",
    "    nan_counts = df.isna().sum().to_dict()\n",
    "    return nan_counts\n",
    "\n",
    "count_nans(df_london)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189218fe",
   "metadata": {},
   "source": [
    "Data exploration space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fedad88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking certain column's unique values\n",
    "column_name = 'Falls within'\n",
    "counts = df_london[column_name].value_counts(dropna=False).to_dict()\n",
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd982dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27205378"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check length\n",
    "len(df_london)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f274a8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where 'Reported by' and 'Falls within' are different: 492\n"
     ]
    }
   ],
   "source": [
    "# Check where 'Reported by' and 'Falls within' are different\n",
    "different_rows = df_london[df_london['Reported by'] != df_london['Falls within']]\n",
    "\n",
    "# Print how number of different rows\n",
    "len(different_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76595f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Surrey Police': 'City of London Police'}\n"
     ]
    }
   ],
   "source": [
    "# Select rows where 'Reported by' and 'Falls within' are different\n",
    "different_rows = df_london[df_london['Reported by'] != df_london['Falls within']]\n",
    "\n",
    "# Create a dictionary: {Reported by : Falls within}\n",
    "diff_dict = dict(zip(different_rows['Reported by'], different_rows['Falls within']))\n",
    "\n",
    "# Print results\n",
    "print(diff_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdd1fa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Reported by column due to redundancy, every value that was 'Surrey Police' will now be 'City of London Police'\n",
    "df_london = df_london.drop(columns=['Reported by'])\n",
    "cleaned_london_data = df_london.rename(columns={'Falls within': 'Falls within/Reported by'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dfcbd1",
   "metadata": {},
   "source": [
    "Converting df into csv file for storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b4d6eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_london_data.to_csv('london_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a13061",
   "metadata": {},
   "source": [
    "SKIP HERE FOR ANALYSIS AND EXPLORATION OF CLEANED FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b1b71",
   "metadata": {},
   "source": [
    "Loading new csv file and getting it ready for future work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b10c7d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "851baf76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Falls within/Reported by</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>LSOA code</th>\n",
       "      <th>Crime type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12</td>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>0.165776</td>\n",
       "      <td>51.5442</td>\n",
       "      <td>On or near Dagenham East</td>\n",
       "      <td>E01000036</td>\n",
       "      <td>Anti-social behaviour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-12</td>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>0.165776</td>\n",
       "      <td>51.5442</td>\n",
       "      <td>On or near Dagenham East</td>\n",
       "      <td>E01000036</td>\n",
       "      <td>Anti-social behaviour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-12</td>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>0.165776</td>\n",
       "      <td>51.5442</td>\n",
       "      <td>On or near Dagenham East</td>\n",
       "      <td>E01000036</td>\n",
       "      <td>Violent crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-12</td>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>0.165776</td>\n",
       "      <td>51.5442</td>\n",
       "      <td>On or near Dagenham East</td>\n",
       "      <td>E01000036</td>\n",
       "      <td>Violent crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-12</td>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>0.165776</td>\n",
       "      <td>51.5442</td>\n",
       "      <td>On or near Dagenham East</td>\n",
       "      <td>E01000036</td>\n",
       "      <td>Violent crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Month  Falls within/Reported by  Longitude  Latitude  \\\n",
       "0  2010-12  British Transport Police   0.165776   51.5442   \n",
       "1  2010-12  British Transport Police   0.165776   51.5442   \n",
       "2  2010-12  British Transport Police   0.165776   51.5442   \n",
       "3  2010-12  British Transport Police   0.165776   51.5442   \n",
       "4  2010-12  British Transport Police   0.165776   51.5442   \n",
       "\n",
       "                   Location  LSOA code             Crime type  \n",
       "0  On or near Dagenham East  E01000036  Anti-social behaviour  \n",
       "1  On or near Dagenham East  E01000036  Anti-social behaviour  \n",
       "2  On or near Dagenham East  E01000036          Violent crime  \n",
       "3  On or near Dagenham East  E01000036          Violent crime  \n",
       "4  On or near Dagenham East  E01000036          Violent crime  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get directory and path for the csv file\n",
    "current_dir2 = os.getcwd()\n",
    "csv_filename2 = 'london_data.csv'  \n",
    "csv_path2 = os.path.join(current_dir2, csv_filename2)\n",
    "\n",
    "df = pd.read_csv(csv_path2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fbee6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
